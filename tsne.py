import torch
import torch.nn as nn
from torch.utils.data import DataLoader
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE
from sklearn.preprocessing import LabelEncoder
import os
import seaborn as sns

# ================= é…ç½®åŒºåŸŸ =================
DATA_FILE = r"D:\PycharmProject\pytorch\libs\final_dataset\Final_Merged_Dataset_1.csv"
OUTPUT_DIR = r"C:\Users\admin\Desktop\æå–ç»“æœ"
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
NUM_CLASSES = 5


# ================= æ¨¡å‹å®šä¹‰ (ä¿æŒåŸç»“æ„ï¼Œåªæ”¹æå–é€»è¾‘) =================
class SpectralCNN(nn.Module):
    def __init__(self, num_classes, input_length):
        super(SpectralCNN, self).__init__()
        # 1. ç‰¹å¾æå–éƒ¨åˆ† (å®Œå…¨ä¿æŒåŸæ ·ï¼Œä»¥å…¼å®¹æ—§æƒé‡ keys)
        self.features = nn.Sequential(
            nn.Conv1d(1, 16, 5, 1, 2), nn.BatchNorm1d(16), nn.ReLU(), nn.MaxPool1d(2),
            nn.Conv1d(16, 32, 5, 1, 2), nn.BatchNorm1d(32), nn.ReLU(), nn.MaxPool1d(2),
            nn.Conv1d(32, 64, 3, 1, 1), nn.BatchNorm1d(64), nn.ReLU(), nn.MaxPool1d(2)
        )

        self.flatten_dim = self._get_flatten_dim(input_length)

        # 2. åˆ†ç±»å™¨éƒ¨åˆ†
        self.classifier = nn.Sequential(
            nn.Linear(self.flatten_dim, 256),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(256, num_classes)
        )

    def _get_flatten_dim(self, length):
        dummy_input = torch.zeros(1, 1, length)
        with torch.no_grad():
            output = self.features(dummy_input)
        return output.view(1, -1).size(1)

    def forward(self, x):
        intermediate_features = {}

        # --- 1. Conv Layers ---
        # ç›´æ¥é€šè¿‡æ•´ä¸ª features åºåˆ— (åˆ°è¾¾ Layer 3 ç»“æŸ)
        x = self.features(x)

        # ã€æå–ç‚¹1ï¼šConv Layerã€‘(å–æœ€åä¸€ä¸ªå·ç§¯å±‚çš„è¾“å‡º)
        # ä¿æŒåŸå§‹çš„ view (Flatten) æ–¹å¼
        intermediate_features['Conv_Feature'] = x.view(x.size(0), -1)

        # --- Flatten ---
        x = x.view(x.size(0), -1)

        # --- 2. FC Layer ---
        x = self.classifier[0](x)  # Linear
        fc_feature = self.classifier[1](x)  # ReLU

        # ã€æå–ç‚¹2ï¼šFC Layerã€‘(è¯­ä¹‰ç‰¹å¾)
        intermediate_features['FC_Feature'] = fc_feature

        # --- 3. Output Layer ---
        x = self.classifier[2](fc_feature)  # Dropout
        out = self.classifier[3](x)  # Linear (Logits)

        # ã€æå–ç‚¹3ï¼šOutput Layerã€‘(æœ€ç»ˆåˆ†ç±»è¾“å‡º)
        intermediate_features['Output_Layer'] = out

        return out, intermediate_features


# ================= ä¸»ç¨‹åº =================

def main():
    if not os.path.exists(OUTPUT_DIR):
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {OUTPUT_DIR}")
        return

    print("ğŸš€ æ­£åœ¨å‡†å¤‡ 2x2 å…¨å±‚çº§ t-SNE åˆ†æ (Raw -> Conv -> FC -> Output)...")

    # 1. è¯»å–æ•°æ®
    try:
        df = pd.read_csv(DATA_FILE)
    except Exception as e:
        print(f"âŒ è¯»å–æ•°æ®å¤±è´¥: {e}")
        return

    y_raw = df.iloc[:, 0].values
    X_raw = df.iloc[:, 2:].values.astype(np.float32)
    input_length = X_raw.shape[1]

    le = LabelEncoder()
    y_enc = le.fit_transform(y_raw)

    # é‡‡æ ·é€»è¾‘ (ä¿æŒåŸå§‹çš„éšæœºé‡‡æ ·)
    SAMPLE_LIMIT = 2280
    if len(X_raw) > SAMPLE_LIMIT:
        print(f" -> æ•°æ®é‡è¾ƒå¤§ ({len(X_raw)})ï¼Œéšæœºé‡‡æ · {SAMPLE_LIMIT} ä¸ªæ ·æœ¬...")
        indices = np.random.choice(len(X_raw), SAMPLE_LIMIT, replace=False)
        X_sample = X_raw[indices]
        y_sample = y_enc[indices]
        y_labels = y_raw[indices]
    else:
        X_sample = X_raw
        y_sample = y_enc
        y_labels = y_raw

    # åˆå§‹åŒ– t-SNE å¯¹è±¡
    tsne = TSNE(n_components=2, random_state=42, init='pca', learning_rate='auto', perplexity=30)

    # ã€å›¾1ã€‘Raw Data
    plot_data = {
        'Labels': y_labels,
        'Raw Data': tsne.fit_transform(X_sample)
    }
    print(" âœ… Raw Data t-SNE å®Œæˆ")

    # 2. åŠ è½½æ¨¡å‹å¹¶æå–ç‰¹å¾
    model = SpectralCNN(NUM_CLASSES, input_length).to(DEVICE)

    try:
        model_files = [f for f in os.listdir(OUTPUT_DIR) if f.endswith('.pth')]
        if not model_files: raise FileNotFoundError("æœªæ‰¾åˆ° .pth æ¨¡å‹æ–‡ä»¶")
        model_name = "best_model.pth" if "best_model.pth" in model_files else model_files[0]
        model_path = os.path.join(OUTPUT_DIR, model_name)
        print(f" -> åŠ è½½æ¨¡å‹: {model_name}")

        model.load_state_dict(torch.load(model_path))
        model.eval()

        # å‡†å¤‡æ•°æ® Tensor
        X_tensor = torch.FloatTensor(X_sample).unsqueeze(1).to(DEVICE)

        # å®¹å™¨ï¼šåªæ”¶é›†æˆ‘ä»¬éœ€è¦çš„3ä¸ªå±‚
        collected_features = {
            'Conv_Feature': [],
            'FC_Feature': [],
            'Output_Layer': []
        }

        batch_size = 256
        with torch.no_grad():
            for i in range(0, len(X_tensor), batch_size):
                batch = X_tensor[i:i + batch_size]
                _, batch_feats = model(batch)

                # å°†æ¯ä¸ª batch çš„ç‰¹å¾è½¬å› numpy å¹¶å­˜å…¥åˆ—è¡¨
                for key in collected_features:
                    collected_features[key].append(batch_feats[key].cpu().numpy())

        # åˆå¹¶ batch å¹¶è®¡ç®— t-SNE
        print(" -> å¼€å§‹è®¡ç®—ç‰¹å¾ t-SNE (è¯·è€å¿ƒç­‰å¾…)...")

        # æ˜ å°„æ˜¾ç¤ºçš„åç§°
        layer_display_names = {
            'Conv_Feature': 'Conv Layer (Last)',
            'FC_Feature': 'FC Layer (Dense)',
            'Output_Layer': 'Output Layer (Result)'
        }

        for key, batches in collected_features.items():
            # æ‹¼æ¥
            feat_matrix = np.concatenate(batches, axis=0)
            # è®¡ç®— t-SNE
            print(f"    ...è®¡ç®— {key} çš„ t-SNE")
            tsne_result = tsne.fit_transform(feat_matrix)
            # å­˜å…¥ç»˜å›¾æ•°æ®
            plot_data[layer_display_names[key]] = tsne_result

    except Exception as e:
        print(f"âš ï¸ ç‰¹å¾æå–æˆ– t-SNE è®¡ç®—å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return

    # 3. å¯¼å‡ºæ•°æ®åˆ° CSV
    print("\nğŸ’¾ æ­£åœ¨å¯¼å‡ºæ•°æ®...")
    export_df = pd.DataFrame({'Label': y_labels})
    for name, coords in plot_data.items():
        if name != 'Labels':
            export_df[f'{name}_X'] = coords[:, 0]
            export_df[f'{name}_Y'] = coords[:, 1]

    csv_path = os.path.join(OUTPUT_DIR, "Four_Layers_tSNE_Data.csv")
    export_df.to_csv(csv_path, index=False)
    print(f"âœ… æ•°æ®å·²ä¿å­˜: {csv_path}")

    # 4. ç»˜åˆ¶ 2x2 çš„å¤šå­å›¾
    print("ğŸ¨ ç”Ÿæˆ 2x2 æ¼”åŒ–å›¾...")
    fig, axes = plt.subplots(2, 2, figsize=(16, 14))  # æ”¹ä¸º 2x2 å¸ƒå±€
    axes = axes.flatten()

    # å®šä¹‰ç»˜å›¾é¡ºåº
    plot_order = [
        'Raw Data',
        'Conv Layer (Last)',
        'FC Layer (Dense)',
        'Output Layer (Result)'
    ]

    # è°ƒè‰²æ¿
    palette = sns.color_palette("tab10", n_colors=len(np.unique(y_labels)))

    for i, name in enumerate(plot_order):
        ax = axes[i]
        coords = plot_data[name]

        sns.scatterplot(
            x=coords[:, 0], y=coords[:, 1], hue=y_labels,
            palette=palette, s=50, alpha=0.7, ax=ax, legend='full' if i == 0 else False
        )
        ax.set_title(name, fontsize=16, fontweight='bold')
        ax.set_xticks([])
        ax.set_yticks([])
        ax.set_xlabel('')
        ax.set_ylabel('')

        # ç»™å­å›¾åŠ ä¸ªè¾¹æ¡†ï¼Œå¥½çœ‹ç‚¹
        for spine in ax.spines.values():
            spine.set_edgecolor('#333333')

    # æ·»åŠ æ•´ä½“æ ‡é¢˜
    plt.suptitle("Feature Evolution: Raw -> Conv -> FC -> Output", fontsize=20, y=0.96)

    # è°ƒæ•´å¸ƒå±€
    plt.tight_layout(rect=[0, 0, 1, 0.95])

    save_path = os.path.join(OUTPUT_DIR, "2x2_Evolution.png")
    plt.savefig(save_path, dpi=300)
    plt.show()
    print(f"âœ… å›¾ç‰‡å·²ä¿å­˜: {save_path}")


if __name__ == '__main__':
    main()